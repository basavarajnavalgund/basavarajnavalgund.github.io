<!DOCTYPE html>
<html>
<head>
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Projects - Basavaraj Navalgund</title><link rel="apple-touch-icon" sizes="180x180" href="https://basavarajnavalgund.github.io/image/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="https://basavarajnavalgund.github.io/image/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="https://basavarajnavalgund.github.io/image/favicon-16x16.png">
	<link rel="manifest" href="https://basavarajnavalgund.github.io/image/site.webmanifest">
	<link rel="mask-icon" href="https://basavarajnavalgund.github.io/safari-pinned-tab.svg" color="#5bbad5">
	<meta name="msapplication-TileColor" content="#da532c">
	<meta name="theme-color" content="#ffffff">

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta property="og:title" content="Projects" />
<meta property="og:description" content="Here is a collection of notes I have prepared in the past on various topics of interest.
 Semi-supervised Expectation Maximization This work considers the Expectation Maximization (EM) algorithm in the semi-supervised setting. First, the general form for semi-supervised version of maximum likelihood is derived from the Latent Variable Model (LVM). Since the involved integrals are usually intractable, a surrogate objective function based on the Evidence Lower Bound (ELBO) is introduced." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://basavarajnavalgund.github.io/pages/notes/" />
<meta property="article:published_time" content="2021-02-03T14:39:22+01:00" />
<meta property="article:modified_time" content="2021-02-03T14:39:22+01:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Projects"/>
<meta name="twitter:description" content="Here is a collection of notes I have prepared in the past on various topics of interest.
 Semi-supervised Expectation Maximization This work considers the Expectation Maximization (EM) algorithm in the semi-supervised setting. First, the general form for semi-supervised version of maximum likelihood is derived from the Latent Variable Model (LVM). Since the involved integrals are usually intractable, a surrogate objective function based on the Evidence Lower Bound (ELBO) is introduced."/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://basavarajnavalgund.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://basavarajnavalgund.github.io/css/main.css"/>

	<script src="https://basavarajnavalgund.github.io/js/feather.min.js"></script><script src="https://basavarajnavalgund.github.io/js/main.js"></script>
</head>


<body>
    <div id="content">





<div class="header wrapper">
  <span class="page_title">
    Projects
  </span>
  <ul class="flat">
    <li class="page_meta">December 2, 2021</li>
  </ul>
  <a href="https://basavarajnavalgund.github.io" title="Home" class="page_meta">[home]</a>
</div>

<div class="content wrapper">
  <p>Here is a collection of notes I have prepared in the past on various topics of interest.</p>
<!-- raw HTML omitted -->
<h4 id="hahahugoshortcode-s0-hbhb-lidar-robot-mapping"><i class="feather-16" data-feather="corner-down-right"></i> lidar_robot_mapping  (ROS, Autoware, Gazebo, C++)</h4>
<p>Hands-on Experience with RS–LiDAR-16, OS2–64, and OS2–128 to build an occupancy grid of controlled
	environment. Fusion of slam toolbox with Autoware package based NDT Mapping to get odom to baselink
	transformation and, accurate 2D SLAM.<br>

<h4 id="hahahugoshortcode-s1-hbhb-t265-robot-navigation"><i class="feather-16" data-feather="corner-down-right"></i> t265_robot_navigation (ROS, Gazebo, C++)</h4>
<p>Using a Intel Realsense T265 to build an occupancy grid and autonomously navigate around using move_base.<br>
<a href="https://github.com/basavarajnavalgund/t265_robot_navigation/">[code]</a>

<h4 id="hahahugoshortcode-s2-hbhb-workplace-service-robot"><i class="feather-16" data-feather="corner-down-right"></i> Workplace Service Robot (ROS, Gazebo, C++, Python)</h4>
<p>Autonomous Mobile Robot (AMR), a holonomic drive with 4 mecanum-wheels. It autonomously maps an
	environment, localizes itself, and navigate to pick-up and drop-off objects in a simulated environment.<br>
<a href="https://basavarajnavalgund.github.io/Workplace-Service-Robot/">[code]</a></p>

<h4 id="hahahugoshortcode-s3-hbhb-sensor-fusion-based-tracking"><i class="feather-16" data-feather="corner-down-right"></i> Sensor fusion-based Tracking (C++)</h4>
<p>Utilize sensor data from both LIDAR and RADAR measurements for object (e.g. pedestrian, vehicles, or other moving objects) tracking with the <a href="https://basavarajnavalgund.github.io/tracking-with-Kalman-Filter/">Kamlan Filter</a>, <a href="https://basavarajnavalgund.github.io/tracking-with-Extended-Kalman-Filter/">Extended Kamlan Filter</a>, and <a href="https://basavarajnavalgund.github.io/tracking-with-Unscented-Kalman-Filter/">Unscented Kamlan Filter</a>.<br>

<h4 id="hahahugoshortcode-s2-hbhb-vehicle-localization"><i class="feather-16" data-feather="corner-down-right"></i> Vehicle Localization (C++)</h4>
<p>The Vehicle has been “kidnapped” and transported to a new location! Luckily it has a map of this location and a (noisy) GPS estimate of its initial location. Then the vehicle starts to move, in the meanwhile, it records the noisy sensor and control data. A real-time particle filter is implemented to localize the vehicle with the sensor data. 
	In this project, particle filter will be given a map and some initial localization information (analogous to what a GPS would provide). At each time step my filter will also get observation and control data.<br>
<a href="https://basavarajnavalgund.github.io/vehicle-localization/">[code]</a></p>

<h4 id="hahahugoshortcode-s2-hbhb-path-planning"><i class="feather-16" data-feather="corner-down-right"></i> Path Planning (C++)</h4>
<p>Implemented a simple real-time path planner in C++ to navigate a car around a simulated highway scenario,
	including other traffic, given waypoint, and sensor fusion data.<br>
<a href="https://basavarajnavalgund.github.io/path_planning/">[code]</a></p>

<h4 id="hahahugoshortcode-s2-hbhb-model-predictive-control"><i class="feather-16" data-feather="corner-down-right"></i> Model Predictive Control (C++)</h4>
<p>Implemented a Model Predictive Control (MPC) to drive a car in a game simulator. The server provides reference
	waypoints via websocket, and we use MPC to optimize the actuators (steering and throttle), simulate the vehicle
	trajactory, and minimize the cost like cross-track error.<br>
<a href="https://basavarajnavalgund.github.io/Model-Predictive-Control/">[code]</a></p>

</div>

</div>
    <div class="footer wrapper">
	<nav class="nav">
		<div>Basavaraj Navalgund 2021</div>
	</nav>
</div>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-176158287-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script>
	feather.replace()
</script>
</body>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

</html>